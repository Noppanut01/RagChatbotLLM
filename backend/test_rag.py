#!/usr/bin/env python3

# Quick test to verify llama3.2 integration
from langchain_ollama import OllamaLLM
from langchain_ollama import OllamaEmbeddings

print("Testing llama3.2 integration...")

try:
    # Test LLM
    llm = OllamaLLM(model="llama3.2", temperature=0.3)
    response = llm.invoke("à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡ llama3.2 à¸•à¸­à¸šà¸ªà¸±à¹‰à¸™à¹†")
    print(f"âœ… LLM Test Success: {response}")
    
    # Test Embeddings
    embeddings = OllamaEmbeddings(model="mxbai-embed-large")
    test_embedding = embeddings.embed_query("à¸—à¸”à¸ªà¸­à¸š embedding")
    print(f"âœ… Embeddings Test Success: Vector dimension = {len(test_embedding)}")
    
    print("\nğŸ‰ All tests passed! llama3.2 is ready to use.")
    
except Exception as e:
    print(f"âŒ Error: {e}")
